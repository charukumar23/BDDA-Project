{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder as onehot\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"springleaf-marketing-response/train.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_traincp = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_traincp.shape\n",
    "print()\n",
    "df_traincp.head()\n",
    "print()\n",
    "df_traincp.dtypes.value_counts()\n",
    "print()\n",
    "df_traincp.describe()\n",
    "print()\n",
    "df_traincp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_traincp.drop('ID', axis = 'columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_traincp['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_traincp.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--Current memory usage (MB) --\\n\")\n",
    "df_traincp.memory_usage().sum()/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_traincp:\n",
    "    if df_traincp[column].dtypes == 'int64':\n",
    "        print(\"int:\", column)\n",
    "        df_traincp[column]=df_traincp[column].astype('uint8')\n",
    "    elif df_traincp[column].dtypes == 'float64':\n",
    "        print(\"float:\", column)\n",
    "        df_traincp[column]=df_traincp[column].astype('uint8')\n",
    "df_traincp.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--Revised memory usage (MB) --\\n\")\n",
    "df_traincp.memory_usage().sum()/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1_train=df_train\n",
    "#df1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_traincp:\n",
    "    column\n",
    "    print(\"No. of unique values:\", df_traincp[column].nunique())\n",
    "    print(\"No.of Null Values:\", df_traincp[column].isnull().sum())\n",
    "    \n",
    "    if df_traincp[column].nunique()==1:\n",
    "        df_traincp.drop(column, axis='columns', inplace=True)\n",
    "    elif df_traincp[column].isnull().sum()/len(df_traincp[column])>=0.6:\n",
    "        df_traincp.drop(column, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_traincp.shape\n",
    "df_traincp.head()\n",
    "df_traincp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1_train.drop(column, axis='columns', inplace=True)\n",
    "df_train.shape\n",
    "Target=df_traincp.pop('target')\n",
    "df_traincp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_traincp.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols2 = df_traincp.select_dtypes(include=[np.object]).columns\n",
    "cat_cols2 = cat_cols2.tolist()\n",
    "len(cat_cols2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl1 = (df_traincp.nunique()<=30)\n",
    "cat_cols3 = cl1[cl1==True].index.tolist()\n",
    "len(cat_cols3)\n",
    "cat_cols3.extend(cat_cols2)\n",
    "len(cat_cols3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols4=[]\n",
    "for i in cat_cols3:\n",
    "    if i not in cat_cols4:\n",
    "        cat_cols4.append(i)\n",
    "len(cat_cols4)\n",
    "cat_cols4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols1 = df_traincp.select_dtypes(include=[np.number]).columns\n",
    "num_cols1 = num_cols1.tolist()\n",
    "len(num_cols1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in cat_cols4:\n",
    "    if element in num_cols1:\n",
    "        num_cols1.remove(element)\n",
    "\n",
    "len(num_cols1)\n",
    "num_cols1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No. of Categorical columns: \", len(cat_cols4))\n",
    "print(\"No. of Numerical Columns: \", len(num_cols1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_traincp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_mean = num_cols1\n",
    "cat_cols_mf = cat_cols4\n",
    "num_cols_mean\n",
    "cat_cols_mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[num_cols_mean] # Num dataset, impute by 'mean' strategy\n",
    "print()\n",
    "X_train[num_cols_mean].dtypes.value_counts()\n",
    "print('No. of null values in numerical coulmns: ', X_train[num_cols_mean].isnull().sum().sum())\n",
    "len(X_train[num_cols_mean])\n",
    "X_train[num_cols_mean].shape\n",
    "\n",
    "\n",
    "X_train[cat_cols_mf] # Cat dataset, impute by 'most_frequent' strategy\n",
    "print()\n",
    "X_train[cat_cols_mf].dtypes.value_counts()\n",
    "print('No. of null values in categorical coulmns: ', X_train[cat_cols_mf].isnull().sum().sum())\n",
    "len(X_train[cat_cols_mf])\n",
    "X_train[cat_cols_mf].shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_c = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_train[num_cols_mean]:\n",
    "    X_train[col].fillna(X_train[col].mean(), inplace=True)\n",
    "\n",
    "for col in X_train[cat_cols_mf]:\n",
    "    X_train[col].fillna(X_train[col].mode(), inplace=True)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dropna(axis=0, inplace=True)\n",
    "X_train.shape\n",
    "for cols in X_train[num_cols_mean]:\n",
    "    if X_train[cols].dtypes=='float16':\n",
    "        X_train[cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in X_test:\n",
    "#    if X_test[col].dtypes=='uint16':\n",
    "#        X_test[col].fillna(X_test[col].mean(), inplace=True)\n",
    "#\n",
    "#for col in X_test:        \n",
    "#    if X_test[col].dtypes=='float16':\n",
    " #       X_test[col].fillna(X_test[col].mean(), inplace=True)\n",
    "#\n",
    "#for col in X_train[cat_cols_mf]:\n",
    "#    if X_test[col].dtypes=='object':\n",
    "#        X_train[col].fillna(X_train[col].mode(), inplace=True)\n",
    "#\n",
    "#X_test.shape\n",
    "#\n",
    "#X_test.dropna(axis=0, inplace=True)\n",
    "#X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[cat_cols_mf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[cat_cols_mf].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[['VAR_0404', 'VAR_0466', 'VAR_0467', 'VAR_0493']].nunique(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['VAR_0466'].value_counts() / X_train.shape[0]\n",
    "X_train['VAR_0467'].value_counts() / X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['VAR_0075', 'VAR_0204', 'VAR_0217']\n",
    "locations = ['VAR_200', 'VAR_0237', 'VAR_274']\n",
    "\n",
    "date1 = pd.to_datetime(X_train[\"VAR_0075\"],format = '%d%b%y:%H:%M:%S')\n",
    "date2 = pd.to_datetime(X_train[\"VAR_0217\"],format = '%d%b%y:%H:%M:%S')\n",
    "np.all(date2 > date1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "year_func = lambda x: datetime.strptime(x, \"%d%b%y:%H:%M:%S\" ).year\n",
    "month_func = lambda x: datetime.strptime(x, \"%d%b%y:%H:%M:%S\" ).month\n",
    "day_func = lambda x: datetime.strptime(x, \"%d%b%y:%H:%M:%S\" ).day\n",
    "hour_func = lambda x: datetime.strptime(x, \"%d%b%y:%H:%M:%S\" ).hour\n",
    "minute_func = lambda x: datetime.strptime(x, \"%d%b%y:%H:%M:%S\" ).minute\n",
    "\n",
    "enc_data =  pd.DataFrame(index=X_train.index)\n",
    "for col in X_train[cat_cols_mf]:\n",
    "    enc_data[col] = X_train[col].factorize()[0]\n",
    "    if col in dates:\n",
    "        enc_data[col + '_year'] = X_train[col].map(year_func)\n",
    "        enc_data[col + '_month'] = X_train[col].map(month_func)\n",
    "        enc_data[col + '_day'] = X_train[col].map(day_func)\n",
    "        enc_data[col + '_hour'] = X_train[col].map(hour_func)\n",
    "        enc_data[col + '_minute'] = X_train[col].map(minute_func)\n",
    "expanded_categoricals = list(enc_data.columns) # saving which variables are categorical for possible one hot encoding \n",
    "enc_data[\"target\"] = Target\n",
    "# finding correlation and looking at it\n",
    "corrmat = enc_data.corr()\n",
    "corrmat[\"target\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(df_train.target.value_counts() *100/ df_train.target.count(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 500 # number of samples to use from each class of target for dimensionality reduction, reduce this if you are impatient!\n",
    "numerical_feats = X_train[num_cols_mean]\n",
    "new_data = pd.concat([numerical_feats, enc_data], axis=1)\n",
    "positive_samples = new_data[new_data['target'] == 1].sample(num_samples)\n",
    "negative_samples = new_data[new_data['target'] == 0].sample(num_samples)\n",
    "to_transform = pd.concat([positive_samples, negative_samples]).sample(frac=1).reset_index(drop=True)\n",
    "to_transform.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = to_transform.drop(['target'], axis=1, inplace=False)\n",
    "labels = to_transform['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_embedding =  PCA(n_components=2) \n",
    "pca_emb_data = pca_embedding.fit_transform(features.values)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(pca_emb_data[labels == 1, 0], pca_emb_data[labels == 1, 1], color='red', label='positive samples')\n",
    "plt.scatter(pca_emb_data[labels == 0, 0], pca_emb_data[labels == 0, 1], color='blue', label='negative samples')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit_transform(X_train[num_cols_mean])\n",
    "a= ss.transform(X_train[num_cols_mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder as onehot\n",
    "\n",
    "ohe = onehot(sparse = False)\n",
    "b=ohe.fit_transform(X_train[cat_cols_mf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack([a,b]) #Let X be the new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(\n",
    "                                                    X,                   # Data features\n",
    "                                                    Target,                   # Target column\n",
    "                                                    test_size = 0.2, random_state = 100     # split-ratio\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For imbalanced dataset:\n",
    "sm = SMOTE(random_state = 3)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "  \n",
    "print('X_train shape after oversampling: {}'.format(X_train_res.shape))\n",
    "print('Y_train shape after oversampling: {} \\n'.format(y_train_res.shape))\n",
    "  \n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import tree\n",
    "dt = DecisionTreeClassifier(criterion = 'entropy',random_state = 0,max_depth=5)\n",
    "dt.fit(X_train_res,y_train_res)\n",
    "y_prediction = dt.predict(X_test)\n",
    "print(classification_report(y_test, y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_rf = RandomForestClassifier()\n",
    "model_rf.fit(X_train_res, y_train_res)\n",
    "y_predicted = model_rf.predict(X_test)\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train_res, y_train_res)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
